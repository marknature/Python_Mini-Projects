{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fashion Recommender System | Clothes Recommendation | Ecommerce Project\n# app.py\n\n# import\nimport tensorflow\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\nimport numpy as np\nfrom numpy.linalg import norm\nimport os\nfrom tqdm import tqdm\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel.trainable = False\n\nmodel = tensorflow.keras.Sequential([\n    model,\n    GlobalMaxPooling2D()\n])\n\n#print(model.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(img_path,model):\n    img = image.load_img(img_path,target_size=(224,224))\n    img_array = image.img_to_array(img)\n    expanded_img_array = np.expand_dims(img_array, axis=0)\n    preprocessed_img = preprocess_input(expanded_img_array)\n    result = model.predict(preprocessed_img).flatten()\n    normalized_result = result / norm(result)\n\n    return normalized_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = []\n\nfor file in os.listdir('images'):\n    filenames.append(os.path.join('images',file))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_list = []\n\nfor file in tqdm(filenames):\n    feature_list.append(extract_features(file,model))\n\npickle.dump(feature_list,open('embeddings.pkl','wb'))\npickle.dump(filenames,open('filenames.pkl','wb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test.py\n# imports\nimport pickle\nimport tensorflow\nimport numpy as np\nfrom numpy.linalg import norm\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom sklearn.neighbors import NearestNeighbors\nimport cv2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start testing algorithm\nfeature_list = np.array(pickle.load(open('embeddings.pkl', 'rb')))\nfilenames = pickle.load(open('filenames.pkl', 'rb'))\n\nmodel = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nmodel.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tensorflow.keras.Sequential([\n    model,\n    GlobalMaxPooling2D()\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = image.load_img('3456.jpeg', target_size=(224, 224))\nimg_array = image.img_to_array(img)\nexpanded_img_array = np.expand_dims(img_array, axis=0)\npreprocessed_img = preprocess_input(expanded_img_array)\nresult = model.predict(preprocessed_img).flatten()\nnormalized_result = result / norm(result)\n\nneighbors = NearestNeighbors(n_neighbors=6, algorithm='brute', metric='euclidean')\nneighbors.fit(feature_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distances, indices = neighbors.kneighbors([normalized_result])\n# Test\nprint(indices)\n# for loop\nfor file in indices[0][1:6]:\n    temp_img = cv2.imread(filenames[file])\n    cv2.imshow('output', cv2.resize(temp_img, (512, 512)))\n    cv2.waitKey(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports\nimport streamlit as st\nimport os\nfrom PIL import Image\nimport numpy as np\nimport pickle\nimport tensorflow\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\nfrom sklearn.neighbors import NearestNeighbors\nfrom numpy.linalg import norm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_list = np.array(pickle.load(open('embeddings.pkl','rb')))\nfilenames = pickle.load(open('filenames.pkl','rb'))\n\nmodel = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel.trainable = False\n\nmodel = tensorflow.keras.Sequential([\n    model,\n    GlobalMaxPooling2D()\n])\n\nst.title('Fashion Recommender System')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_uploaded_file(uploaded_file):\n    try:\n        with open(os.path.join('uploads',uploaded_file.name),'wb') as f:\n            f.write(uploaded_file.getbuffer())\n        return 1\n    except:\n        return 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_extraction(img_path,model):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    expanded_img_array = np.expand_dims(img_array, axis=0)\n    preprocessed_img = preprocess_input(expanded_img_array)\n    result = model.predict(preprocessed_img).flatten()\n    normalized_result = result / norm(result)\n\n    return normalized_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend(features,feature_list):\n    neighbors = NearestNeighbors(n_neighbors=6, algorithm='brute', metric='euclidean')\n    neighbors.fit(feature_list)\n\n    distances, indices = neighbors.kneighbors([features])\n\n    return indices","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# steps\n# file upload -> save\nuploaded_file = st.file_uploader(\"Choose an image\")\nif uploaded_file is not None:\n    if save_uploaded_file(uploaded_file):\n        # display the file\n        display_image = Image.open(uploaded_file)\n        st.image(display_image)\n        # feature extract\n        features = feature_extraction(os.path.join(\"uploads\",uploaded_file.name),model)\n        #st.text(features)\n        # recommendention\n        indices = recommend(features,feature_list)\n        # show\n        col1,col2,col3,col4,col5 = st.beta_columns(5)\n\n        with col1:\n            st.image(filenames[indices[0][0]])\n        with col2:\n            st.image(filenames[indices[0][1]])\n        with col3:\n            st.image(filenames[indices[0][2]])\n        with col4:\n            st.image(filenames[indices[0][3]])\n        with col5:\n            st.image(filenames[indices[0][4]])\n    else:\n        st.header(\"Some error occured in file upload\")","metadata":{},"execution_count":null,"outputs":[]}]}